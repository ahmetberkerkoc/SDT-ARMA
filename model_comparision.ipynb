{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "import itertools\n",
    "\n",
    "#models\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "def MAPE(y_test, pred):\n",
    "    mape = np.mean(np.abs((y_test - pred) / y_test))\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = \"y\"\n",
    "test_size = 0.3\n",
    "date_column_name = \"date\"\n",
    "model_name = \"lightgbm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"DailyDelhiClimate.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df = df.drop(\"Unnamed: 0\",axis=1)\n",
    "\n",
    "if date_column_name is not None:\n",
    "    df = df.drop(date_column_name, axis=1)\n",
    "col_list = list(df.columns)\n",
    "col_list.remove(label_name)\n",
    "col_list.insert(0, label_name)\n",
    "\n",
    "df = df[col_list]\n",
    "\n",
    "y = df.loc[:,\"y\"]\n",
    "X = df.iloc[:,1:]\n",
    "\n",
    "data_len = len(X)\n",
    "forecast_horizion = int(data_len * test_size)\n",
    "\n",
    "X_train, X_test = X.iloc[:-forecast_horizion], X.iloc[-forecast_horizion:]\n",
    "y_train, y_test = y.iloc[:-forecast_horizion], y.iloc[-forecast_horizion:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dic = {\n",
    "    \"lightgbm\": lgb.LGBMRegressor(),\n",
    "    \"xgboost\": xgb.XGBRegressor(),\n",
    "    \"catboost\": cb.CatBoostRegressor(),\n",
    "    \"decision_tree\": DecisionTreeRegressor()\n",
    " }\n",
    "\n",
    "search_param_dic = {\n",
    "    \"lightgbm\": {\n",
    "            \"n_estimators\": [100, 250, 500, 750, 1000],\n",
    "            \"learning_rate\": [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "            \"num_leaves\": [15, 31, 63, 127, 255],\n",
    "            \"max_depth\": [4, 6, 7, 8, 10],\n",
    "            \"subsample\": [0.4, 0.6, 0.7, 0.9],\n",
    "            \"subsample_freq\": [1, 5, 10, 20, 50],\n",
    "            \"colsample_bytree\": [0.4, 0.6, 0.7, 0.9],\n",
    "            \"reg_alpha\": [0, 0.01, 0.05, 0.5, 1, 10],\n",
    "            \"reg_lambda\": [0, 0.01, 0.05, 0.5, 1, 10],\n",
    "            \"max_bin\": [15, 31, 63, 127, 255],\n",
    "            \"random_state\": [0],\n",
    "            \"verbose\": [-1],\n",
    "        },\n",
    "    \"xgboost\": {\n",
    "            \"n_estimators\": [100, 250, 500, 750, 1000],\n",
    "            \"learning_rate\": [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "            \"num_leaves\": [15, 31, 63, 127, 255],\n",
    "            \"max_depth\": [4, 6, 7, 8, 10],\n",
    "            \"subsample\": [0.4, 0.6, 0.7, 0.9],\n",
    "            \"subsample_freq\": [1, 5, 10, 20, 50],\n",
    "            \"colsample_bytree\": [0.4, 0.6, 0.7, 0.9],\n",
    "            \"reg_alpha\": [0, 0.01, 0.05, 0.5, 1, 10],\n",
    "            \"reg_lambda\": [0, 0.01, 0.05, 0.5, 1, 10],\n",
    "            \"max_bin\": [15, 31, 63, 127, 255],\n",
    "            \"random_state\": [0],\n",
    "            \"verbose\": [-1],\n",
    "        },\n",
    "    \"catboost\": {\n",
    "        \"iterations\": [100, 300, 500, 1000],\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "        \"depth\": [4, 6, 8, 10],\n",
    "        \"l2_leaf_reg\": [1, 3, 5, 7, 9],\n",
    "        \"border_count\": [32, 64, 128, 254],\n",
    "        \"random_strength\": [0, 0.1, 0.5, 1],\n",
    "        \"random_seed\": [0],\n",
    "    }\n",
    ",\n",
    "    \"decision_tree\": {\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"max_depth\": [2, 3, 4, 5, 10, 12],\n",
    "        \"min_samples_split\": [2, 5, 10, 20],\n",
    "        \"min_samples_leaf\": [1, 2, 4, 10],\n",
    "}\n",
    " }\n",
    "\n",
    "\n",
    "model = model_dic[model_name]\n",
    "searching_params = search_param_dic[model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold-out Validation\n",
    "xv_cls = RandomizedSearchCV\n",
    "val_size = forecast_horizion\n",
    "train_val_indexes = np.zeros_like(y_train)\n",
    "train_val_indexes[:-val_size] = -1\n",
    "fold_size = PredefinedSplit(test_fold=train_val_indexes)\n",
    "\n",
    "xv = xv_cls(estimator=model, param_distributions=searching_params, n_iter=10000, scoring=\"neg_mean_absolute_error\", n_jobs=-1,\n",
    "                    cv=fold_size, verbose=-1, refit=False)\n",
    "\n",
    "xv.fit(X_train, y_train)\n",
    "\n",
    "best_params = xv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X.iloc[:-forecast_horizion], X.iloc[-forecast_horizion:]\n",
    "y_train, y_test = y.iloc[:-forecast_horizion], y.iloc[-forecast_horizion:]\n",
    "\n",
    "best_model = type(model)(**best_params).fit(X_train, y_train)\n",
    "preds = best_model.predict(X_train)\n",
    "fores = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse_score = mse(y_train,preds)\n",
    "train_mae_score = mae(y_train,preds)\n",
    "train_mape_score = MAPE(y_train,preds)\n",
    "\n",
    "test_mse_score = mse(y_test,fores)\n",
    "test_mae_score = mae(y_test,fores)\n",
    "test_mape_score = MAPE(y_test,fores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_train,label = \"target\")\n",
    "plt.plot(preds,label=\"preds\")\n",
    "plt.legend()\n",
    "plt.title(\"Train Targets vs Train Preds\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(y_test,label = \"target\")\n",
    "plt.plot(fores,label=\"fores\")\n",
    "plt.legend()\n",
    "plt.title(\"Test Labels vs Test Forecasts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df = df.drop(\"Unnamed: 0\",axis=1)\n",
    "\n",
    "if date_column_name is not None:\n",
    "    df = df.drop(date_column_name, axis=1)\n",
    "col_list = list(df.columns)\n",
    "col_list.remove(label_name)\n",
    "col_list.insert(0, label_name)\n",
    "\n",
    "df = df[col_list]\n",
    "\n",
    "y = df.loc[:,\"y\"]\n",
    "X = df.iloc[:,1:]\n",
    "\n",
    "data_len = len(X)\n",
    "forecast_horizion = int(data_len * test_size)\n",
    "\n",
    "value = y\n",
    "train_value = X.iloc[:-forecast_horizion]\n",
    "test_value = X.iloc[-forecast_horizion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the parameter space for grid search\n",
    "p = d = q = range(0, 3)  # Example range, adjust as necessary\n",
    "P = D = Q = range(0, 3)  # Example range, adjust as necessary\n",
    "s = [12,24]  # Seasonal period, adjust based on your data's seasonality\n",
    "\n",
    "\n",
    "best_mse = float(\"inf\")\n",
    "for param in [(x[0], x[1], x[2]) for x in itertools.product(p, d, q)]:\n",
    "    for seasonal_param in [(x[0], x[1], x[2], x[3]) for x in itertools.product(P, D, Q, s)]:\n",
    "\n",
    "        arima_model = ARIMA(\n",
    "                        value[:-2*forecast_horizion],\n",
    "                        order=param,\n",
    "                        exog=train_value[:-forecast_horizion],\n",
    "                        seasonal_order=seasonal_param\n",
    "                    )\n",
    "        model = arima_model.fit()\n",
    "\n",
    "        start_index = len(train_value)-forecast_horizion\n",
    "        end_index = start_index + forecast_horizion - 1\n",
    "\n",
    "        forecast = model.predict(start=start_index, end=end_index, exog=train_value[-forecast_horizion:])\n",
    "\n",
    "        y_test_np = value[-2*forecast_horizion:-forecast_horizion].to_numpy()\n",
    "        forecast = forecast.to_numpy()\n",
    "        \n",
    "        mse_score = mse(y_test_np, forecast)\n",
    "        mae_score = mae(y_test_np, forecast)\n",
    "        mape_score = MAPE(y_test_np, forecast)\n",
    "        \n",
    "        if mse_score<best_mse:\n",
    "            best_mse = mse_score\n",
    "            best_order = param\n",
    "            best_seasonal_order = seasonal_param\n",
    "        \n",
    "        print(mse_score)\n",
    "        print(mae_score)\n",
    "        print(mape_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = ARIMA(\n",
    "                        value[:-forecast_horizion],\n",
    "                        order=best_order,\n",
    "                        exog=train_value,\n",
    "                        seasonal_order=best_seasonal_order\n",
    "                    )\n",
    "model = best_model.fit()\n",
    "\n",
    "start_index = len(train_value)\n",
    "end_index = start_index + forecast_horizion - 1\n",
    "\n",
    "forecast = model.predict(start=start_index, end=end_index, exog=test_value)\n",
    "\n",
    "y_test_np = value[-forecast_horizion:].to_numpy()\n",
    "forecast = forecast.to_numpy()\n",
    "\n",
    "mse_score = mse(y_test_np, forecast)\n",
    "mae_score = mae(y_test_np, forecast)\n",
    "mape_score = MAPE(y_test_np, forecast)\n",
    "\n",
    "print(mse_score)\n",
    "print(mae_score)\n",
    "print(mape_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.drop(\"Unnamed: 0\",axis=1)\n",
    "\n",
    "if date_column_name is not None:\n",
    "    df = df.drop(date_column_name, axis=1)\n",
    "col_list = list(df.columns)\n",
    "col_list.remove(label_name)\n",
    "col_list.insert(0, label_name)\n",
    "\n",
    "df = df[col_list]\n",
    "\n",
    "y = df.loc[:,\"y\"]\n",
    "X = df.iloc[:,1:]\n",
    "\n",
    "y = y.values\n",
    "X = X.values\n",
    "\n",
    "data_len = len(X)\n",
    "forecast_horizion = int(data_len * test_size)\n",
    "\n",
    "y_train_orig = y[:-forecast_horizion]\n",
    "y_test_orig = y[-forecast_horizion:]\n",
    "\n",
    "feature_shape = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the data\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Create sequences for input and output\n",
    "def create_sequences(data, target, n_steps):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(data) - n_steps):\n",
    "        X_seq.append(data[i : i + n_steps])\n",
    "        y_seq.append(target[i + n_steps])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "n_steps = 10  # number of time steps to look back\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, n_steps)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "X_train, X_test = X_seq[:-forecast_horizion], X_seq[-forecast_horizion:]\n",
    "y_train, y_test = y_seq[:-forecast_horizion], y_seq[-forecast_horizion:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, activation=\"relu\", input_shape=(n_steps, feature_shape)))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_absolute_error\")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "train_loss = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"Training Loss: {train_loss}\")\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform the predictions to the original scale\n",
    "y_train_pred_inv = scaler_y.inverse_transform(y_train_pred).reshape(-1)\n",
    "y_test_pred_inv = scaler_y.inverse_transform(y_test_pred).reshape(-1)\n",
    "\n",
    "y_test = y_test_orig.copy()\n",
    "\n",
    "test_mse_score = mse(y_test, y_test_pred_inv)\n",
    "test_mae_score = mae(y_test, y_test_pred_inv)\n",
    "test_mape_score = MAPE(y_test, y_test_pred_inv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
