{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ahmet\\miniconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "#models\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "def MAPE(y_test, pred):\n",
    "    mape = np.mean(np.abs((y_test - pred) / y_test))\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = \"y\"\n",
    "test_size = 0.3\n",
    "date_column_name = \"date\"\n",
    "model_name = \"lightgbm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"DailyDelhiClimate.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df = df.drop(\"Unnamed: 0\",axis=1)\n",
    "\n",
    "if date_column_name is not None:\n",
    "    df = df.drop(date_column_name, axis=1)\n",
    "col_list = list(df.columns)\n",
    "col_list.remove(label_name)\n",
    "col_list.insert(0, label_name)\n",
    "\n",
    "df = df[col_list]\n",
    "\n",
    "y = df.loc[:,\"y\"]\n",
    "X = df.iloc[:,1:]\n",
    "\n",
    "data_len = len(X)\n",
    "forecast_horizion = int(data_len * test_size)\n",
    "\n",
    "X_train, X_test = X.iloc[:-forecast_horizion], X.iloc[-forecast_horizion:]\n",
    "y_train, y_test = y.iloc[:-forecast_horizion], y.iloc[-forecast_horizion:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dic = {\n",
    "    \"lightgbm\": lgb.LGBMRegressor(),\n",
    "    \"xgboost\": xgb.XGBRegressor(),\n",
    "    \"catboost\": cb.CatBoostRegressor(),\n",
    "    \"decision_tree\": DecisionTreeRegressor()\n",
    " }\n",
    "\n",
    "search_param_dic = {\n",
    "    \"lightgbm\": {\n",
    "            \"n_estimators\": [100, 250, 500, 750, 1000],\n",
    "            \"learning_rate\": [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "            \"num_leaves\": [15, 31, 63, 127, 255],\n",
    "            \"max_depth\": [4, 6, 7, 8, 10],\n",
    "            \"subsample\": [0.4, 0.6, 0.7, 0.9],\n",
    "            \"subsample_freq\": [1, 5, 10, 20, 50],\n",
    "            \"colsample_bytree\": [0.4, 0.6, 0.7, 0.9],\n",
    "            \"reg_alpha\": [0, 0.01, 0.05, 0.5, 1, 10],\n",
    "            \"reg_lambda\": [0, 0.01, 0.05, 0.5, 1, 10],\n",
    "            \"max_bin\": [15, 31, 63, 127, 255],\n",
    "            \"random_state\": [0],\n",
    "            \"verbose\": [-1],\n",
    "        },\n",
    "    \"xgboost\": {\n",
    "            \"n_estimators\": [100, 250, 500, 750, 1000],\n",
    "            \"learning_rate\": [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "            \"num_leaves\": [15, 31, 63, 127, 255],\n",
    "            \"max_depth\": [4, 6, 7, 8, 10],\n",
    "            \"subsample\": [0.4, 0.6, 0.7, 0.9],\n",
    "            \"subsample_freq\": [1, 5, 10, 20, 50],\n",
    "            \"colsample_bytree\": [0.4, 0.6, 0.7, 0.9],\n",
    "            \"reg_alpha\": [0, 0.01, 0.05, 0.5, 1, 10],\n",
    "            \"reg_lambda\": [0, 0.01, 0.05, 0.5, 1, 10],\n",
    "            \"max_bin\": [15, 31, 63, 127, 255],\n",
    "            \"random_state\": [0],\n",
    "            \"verbose\": [-1],\n",
    "        },\n",
    "    \"catboost\": {\n",
    "        \"iterations\": [100, 300, 500, 1000],\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "        \"depth\": [4, 6, 8, 10],\n",
    "        \"l2_leaf_reg\": [1, 3, 5, 7, 9],\n",
    "        \"border_count\": [32, 64, 128, 254],\n",
    "        \"random_strength\": [0, 0.1, 0.5, 1],\n",
    "        \"random_seed\": [0],\n",
    "    }\n",
    ",\n",
    "    \"decision_tree\": {\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"max_depth\": [2, 3, 4, 5, 10, 12],\n",
    "        \"min_samples_split\": [2, 5, 10, 20],\n",
    "        \"min_samples_leaf\": [1, 2, 4, 10],\n",
    "}\n",
    " }\n",
    "\n",
    "\n",
    "model = model_dic[model_name]\n",
    "searching_params = search_param_dic[model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold-out Validation\n",
    "xv_cls = RandomizedSearchCV\n",
    "val_size = forecast_horizion\n",
    "train_val_indexes = np.zeros_like(y_train)\n",
    "train_val_indexes[:-val_size] = -1\n",
    "fold_size = PredefinedSplit(test_fold=train_val_indexes)\n",
    "\n",
    "xv = xv_cls(estimator=model, param_distributions=searching_params, n_iter=10000, scoring=\"neg_mean_absolute_error\", n_jobs=-1,\n",
    "                    cv=fold_size, verbose=-1, refit=False)\n",
    "\n",
    "xv.fit(X_train, y_train)\n",
    "\n",
    "best_params = xv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X.iloc[:-forecast_horizion], X.iloc[-forecast_horizion:]\n",
    "y_train, y_test = y.iloc[:-forecast_horizion], y.iloc[-forecast_horizion:]\n",
    "\n",
    "best_model = type(model)(**best_params).fit(X_train, y_train)\n",
    "preds = best_model.predict(X_train)\n",
    "fores = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse_score = mse(y_train,preds)\n",
    "train_mae_score = mae(y_train,preds)\n",
    "train_mape_score = MAPE(y_train,preds)\n",
    "\n",
    "test_mse_score = mse(y_test,fores)\n",
    "test_mae_score = mae(y_test,fores)\n",
    "test_mape_score = MAPE(y_test,fores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_train,label = \"target\")\n",
    "plt.plot(preds,label=\"preds\")\n",
    "plt.legend()\n",
    "plt.title(\"Train Targets vs Train Preds\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(y_test,label = \"target\")\n",
    "plt.plot(fores,label=\"fores\")\n",
    "plt.legend()\n",
    "plt.title(\"Test Labels vs Test Forecasts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.drop(\"Unnamed: 0\",axis=1)\n",
    "\n",
    "if date_column_name is not None:\n",
    "    df = df.drop(date_column_name, axis=1)\n",
    "col_list = list(df.columns)\n",
    "col_list.remove(label_name)\n",
    "col_list.insert(0, label_name)\n",
    "\n",
    "df = df[col_list]\n",
    "\n",
    "y = df.loc[:,\"y\"]\n",
    "X = df.iloc[:,1:]\n",
    "\n",
    "y = y.values\n",
    "X = X.values\n",
    "\n",
    "data_len = len(X)\n",
    "forecast_horizion = int(data_len * test_size)\n",
    "\n",
    "y_train_orig = y[:-forecast_horizion]\n",
    "y_test_orig = y[-forecast_horizion:]\n",
    "\n",
    "feature_shape = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the data\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Create sequences for input and output\n",
    "def create_sequences(data, target, n_steps):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(data) - n_steps):\n",
    "        X_seq.append(data[i : i + n_steps])\n",
    "        y_seq.append(target[i + n_steps])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "n_steps = 10  # number of time steps to look back\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, n_steps)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "X_train, X_test = X_seq[:-forecast_horizion], X_seq[-forecast_horizion:]\n",
    "y_train, y_test = y_seq[:-forecast_horizion], y_seq[-forecast_horizion:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ahmet\\miniconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ahmet\\miniconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\ahmet\\miniconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "34/34 [==============================] - 1s 4ms/step - loss: 0.1209\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0698\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0608\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0570\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0580\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0554\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0545\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0521\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0529\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0509\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0497\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0500\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0500\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0490\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0504\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0473\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0472\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0481\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0478\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0476\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0478\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0475\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0474\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0475\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0470\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0451\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0452\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0454\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0454\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0448\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0433\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0442\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0433\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0442\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0431\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0428\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0453\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0470\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0456\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0421\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0426\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0431\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0420\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0420\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0437\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0427\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0422\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0416\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0429\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0406\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0416\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0417\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0432\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0413\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0422\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0451\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0432\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0401\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0421\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0407\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0397\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0407\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0401\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0436\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0395\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0401\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0412\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0390\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0423\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0411\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0392\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0393\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0392\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0383\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0388\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0389\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0403\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0413\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0386\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0387\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0392\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0378\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0384\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0403\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0384\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0382\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0394\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0395\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0393\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0386\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0383\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0380\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0379\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0372\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0371\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0387\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0390\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0378\n",
      "Training Loss: 0.03675834462046623\n",
      "Test Loss: 0.05542996898293495\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, activation=\"relu\", input_shape=(n_steps, feature_shape)))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_absolute_error\")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "train_loss = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"Training Loss: {train_loss}\")\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Inverse transform the predictions to the original scale\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_train_pred_inv \u001b[38;5;241m=\u001b[39m scaler_y\u001b[38;5;241m.\u001b[39minverse_transform(\u001b[43my_train_pred\u001b[49m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m y_test_pred_inv \u001b[38;5;241m=\u001b[39m scaler_y\u001b[38;5;241m.\u001b[39minverse_transform(y_test_pred)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m y_train \u001b[38;5;241m=\u001b[39m y_train_orig\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# Inverse transform the predictions to the original scale\n",
    "y_train_pred_inv = scaler_y.inverse_transform(y_train_pred).reshape(-1)\n",
    "y_test_pred_inv = scaler_y.inverse_transform(y_test_pred).reshape(-1)\n",
    "y_train = y_train_orig.copy()\n",
    "y_test = y_test_orig.copy()\n",
    "\n",
    "#Calculate Score\n",
    "train_mse_score = mse(y_train, y_train_pred_inv)\n",
    "train_mae_score = mae(y_train, y_train_pred_inv)\n",
    "train_mape_score = MAPE(y_train, y_train_pred_inv)\n",
    "\n",
    "test_mse_score = mse(y_test, y_test_pred_inv)\n",
    "test_mae_score = mae(y_test, y_test_pred_inv)\n",
    "test_mape_score = MAPE(y_test, y_test_pred_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
